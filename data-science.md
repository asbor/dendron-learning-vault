# Data Science

## Overview

This section contains comprehensive data science learning materials from university courses, covering fundamental concepts, machine learning techniques, statistical analysis, and practical implementations using Python.

## University Courses

### [[data-science.iu-dlmbdsa01]]

**IU International University - Data Science (DLMBDSA01)**

Comprehensive course covering:

- Introduction to data science and machine learning
- Use cases and performance evaluation
- Data preprocessing and processing
- Mathematical techniques (PCA, clustering, regression, time-series)
- AI techniques (SVM, neural networks)
- Exam preparation with examples

**Features**: 7 modules, 156+ slides, extensive Python code examples, exam preparation materials

---

### [[data-science.iau-intelligent-analysis]]

**STU Faculty of Informatics - Intelligent Data Analysis**

Practical-focused course with theory + hands-on exercises:

- 13 comprehensive lecture modules
- 12 weeks of practical Jupyter notebook exercises
- Topics: Python data processing, EDA, cleaning, NLP, ML algorithms, deep learning, big data (Spark)

**Features**: 700+ slides, weekly exercises, project assignments, modern tools (TensorFlow, Spark, NLTK)

---

## Course Comparison

| Aspect | IU DLMBDSA01 | IAU Intelligent Analysis |
|--------|--------------|--------------------------|
| **Institution** | IU International | STU Informatics |
| **Level** | Bachelor/Master | Bachelor |
| **Format** | Self-paced online | Lectures + Weekly labs |
| **Duration** | Semester course | Semester course |
| **Language** | English | Slovak/English |
| **Focus** | Theory + Code examples | Theory + Hands-on exercises |
| **Assessment** | Final exam + assignments | Weekly exercises + Project + Exam |
| **Special Topics** | Time-series forecasting | NLP, Deep learning, Big data (Spark) |

## Learning Path

### Beginner Track

Start with foundational concepts:

1. **IU Module 1**: [[data-science.iu-dlmbdsa01.introduction]] - Core concepts
2. **IAU Week 1-2**: [[data-science.iau-intelligent-analysis.exercises.week-01]], [[data-science.iau-intelligent-analysis.exercises.week-02]] - Python basics
3. **IU Module 2**: [[data-science.iu-dlmbdsa01.use-cases-evaluation]] - Applications

### Intermediate Track

Data processing and analysis:

4. **IU Module 3-4**: Data preprocessing and processing
5. **IAU Week 3-6**: EDA, statistics, cleaning, feature engineering
6. **Both**: Practice with real datasets (Iris, Titanic, House Prices)

### Advanced Track

Machine learning and AI:

7. **IU Module 5**: Mathematical techniques (PCA, clustering, regression)
8. **IAU Week 7-10**: NLP, regression, decision trees
9. **IU Module 6**: AI techniques (SVM, Neural networks)
10. **IAU Week 11-12**: Optimization, deep learning (CNN, LSTM), Spark

## Key Topics Covered

### Data Processing

- Data collection and integration
- Data quality assessment
- Cleaning and transformation
- Missing value handling
- Outlier detection and treatment
- Feature selection and engineering
- Dimensionality reduction (PCA)

### Statistical Analysis

- Descriptive statistics
- Exploratory Data Analysis (EDA)
- Statistical testing and hypothesis testing
- Correlation and causation
- Distributions and probability

### Machine Learning

#### Supervised Learning

- Linear regression
- Logistic regression
- Decision trees and random forests
- Support Vector Machines (SVM)
- Performance evaluation metrics

#### Unsupervised Learning

- K-means clustering
- Hierarchical clustering
- Principal Component Analysis (PCA)

#### Deep Learning

- Artificial Neural Networks (ANNs)
- Convolutional Neural Networks (CNNs)
- Long Short-Term Memory (LSTM)
- Recurrent Neural Networks (RNNs)

### Specialized Topics

- **Natural Language Processing**: Text preprocessing, NLTK, sentiment analysis
- **Time-Series Analysis**: ARIMA, SARIMA, forecasting
- **Optimization**: Genetic algorithms, Monte Carlo simulations
- **Big Data**: Apache Spark, distributed computing
- **Imbalanced Data**: SMOTE, sampling techniques

## Tools and Technologies

### Programming and Environment

- **Python 3.x** - Primary language
- **Jupyter Notebooks** - Interactive development
- **Git** - Version control

### Data Manipulation

- **NumPy** - Numerical computing
- **Pandas** - Data frames and analysis
- **SciPy** - Scientific computing

### Machine Learning

- **Scikit-learn** - ML algorithms and tools
- **Statsmodels** - Statistical models
- **XGBoost/LightGBM** - Gradient boosting

### Deep Learning

- **TensorFlow** - Deep learning framework
- **Keras** - High-level neural network API
- **PyTorch** - Alternative DL framework

### Visualization

- **Matplotlib** - Basic plotting
- **Seaborn** - Statistical visualization
- **Plotly** - Interactive visualizations

### Natural Language Processing

- **NLTK** - Natural Language Toolkit
- **SpaCy** - Industrial-strength NLP
- **TextBlob** - Simplified text processing

### Big Data

- **Apache Spark** - Distributed computing
- **PySpark** - Python API for Spark

## Projects and Applications

### Beginner Projects

1. Iris classification
2. Descriptive statistics analysis
3. Data visualization dashboards

### Intermediate Projects

4. Titanic survival prediction
5. House price regression
6. Customer segmentation (clustering)
7. Time-series forecasting

### Advanced Projects

8. Sentiment analysis system
9. Handwriting recognition (CNN)
10. Time-series prediction (LSTM)
11. Big data processing pipeline (Spark)

## Best Practices

### Data Science Workflow

1. **Problem Definition**: Understand the business/research question
2. **Data Collection**: Gather relevant datasets
3. **Data Exploration**: EDA and visualization
4. **Data Preparation**: Cleaning, transformation, feature engineering
5. **Modeling**: Algorithm selection and training
6. **Evaluation**: Metrics and validation
7. **Deployment**: Production implementation
8. **Monitoring**: Performance tracking and updates

### Code Quality

- Write modular, reusable functions
- Use meaningful variable names
- Document code with comments and docstrings
- Follow PEP 8 style guidelines
- Version control with Git
- Create reproducible environments

### Analysis Best Practices

- Always explore data before modeling
- Handle missing values appropriately
- Scale/normalize features when needed
- Split data (train/validation/test)
- Use cross-validation
- Check for overfitting/underfitting
- Document assumptions and limitations

## Additional Resources

### Mathematics and Statistics

- Linear algebra fundamentals
- Probability theory
- Statistical inference
- Optimization methods

### Books and References

- "Python for Data Analysis" by Wes McKinney
- "Hands-On Machine Learning" by Aurélien Géron
- "Deep Learning" by Goodfellow, Bengio, and Courville
- Course-specific literature in respective sections

### Online Resources

- Scikit-learn documentation
- TensorFlow tutorials
- Kaggle competitions and datasets
- Stack Overflow and data science communities

## Repository Locations

- **IU Course**: `/mnt/c/repos/iu-data-science-DLMBDSA01/`
- **IAU Course**: `/mnt/c/repos/stu-iau_b-intelligent-data-analysis/`

---

## Navigation

- **Parent**: [[root]]
- **IU Course**: [[data-science.iu-dlmbdsa01]]
- **IAU Course**: [[data-science.iau-intelligent-analysis]]

## Related

- [[data-engineering]] - Data engineering coursework
- [[learning.tools]] - Development tools and utilities

## Tags

#data-science #machine-learning #python #statistics #university #courses #analytics
