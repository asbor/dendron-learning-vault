# 7.2 Exam Examples 2

## Question 1

Answers of open-ended questions are examples of the ...

1. nominal data
2. binary data
3. discrete data
4. qualitative data

_**(3 points)**_

<details>

<summary>Answer</summary>

<mark style="color:green;">4. qualitative data</mark>

_Answers of open-ended questions are examples of the qualitative data. The other options listed, such as nominal data, binary data, and discrete data, are all examples of the quantitative data._

</details>

***

## Question 2

The process of merging two variables into a single variable is called ...

1. variable scaling
2. variable decomposition
3. variable corelation analysis
4. variable aggregation

_**(3 points)**_

<details>

<summary>Answer</summary>

<mark style="color:green;">4. variable aggregation</mark>

_The process of merging two variables into a single variable is called variable aggregation. The other options listed, such as variable scaling, variable decomposition, and variable correlation analysis, are all examples of variable transformation methods._

</details>

***

## Question 3

if the classifier output labels a "No" data record as "Yes", the output is called ...

1. a false positive
2. a true positive
3. a true negative
4. a false negative

_**(3 points)**_

<details>

<summary>Answer</summary>

<mark style="color:green;">1. a false positive</mark>

_If the classifier output labels a "No" data record as "Yes", the output is called a false positive. The other options listed, such as a true positive, a true negative, and a false negative, are all examples of correct outputs._

</details>

***

## Question 4

The activation function which generates outputs that are **not** confined to a specific range, is called ...

1. Linear function
2. Step function
3. log sigmoid function
4. tan sigmoid function

_**(3 points)**_

<details>

<summary>Answer</summary>

<mark style="color:green;">1. Linear function</mark>

_The **activation function** which generates outputs that are not confined to a specific range is called a **linear function**. The other options listed, such as step function, log sigmoid function, and tan sigmoid function, all generate outputs that are confined to a specific range._

See chapter:

[#typical-activation-functions](../6.-selected-artificial-intelligence-techniques/6.4-artificial-neural-networks.md#typical-activation-functions "mention")

</details>

***

## Question 5

Which type of chart is used to highlight different types of information when the variables vary greatly?

1. Combo chart
2. Pie chart
3. Bubble chart
4. Area chart

_**(3 points)**_

<details>

<summary>Answer</summary>

<mark style="color:green;">1. Combo chart</mark>

The choice of chart type depends on the specific nature of the information you want to convey, especially when dealing with variables that vary greatly. Here's some context for each option:

1. Combo Chart:
   * A combo chart combines different chart types, like a bar chart and a line chart, in a single visualization.
   * It is useful when you want to compare two or more sets of data with varying scales or types of information in a single chart.
2. Pie Chart:
   * A pie chart is best for showing parts of a whole or the distribution of categories within a dataset.
   * It's less suitable for comparing variables with significant variations unless you're comparing the sizes of individual slices.
3. Bubble Chart:
   * A bubble chart represents data points using bubbles, where the size and position of each bubble convey information.
   * It is effective for displaying three variables: two on the X and Y axes and the third represented by the size of the bubbles. Useful for highlighting variations in multiple dimensions.
4. Area Chart:
   * An area chart is a variation of a line chart where the area beneath the lines is shaded.
   * It is ideal for displaying trends over time or comparing variations in different categories when the variables vary greatly.

The choice between these chart types should be based on the specific characteristics of your data and the message you want to convey.

</details>

***

## Question 6

Which of the following is **not** a variable transformation method?

1. variable aggregation
2. variable extraction
3. variable decomposition
4. variable scaling

_**(3 points)**_

<details>

<summary>Answer</summary>

<mark style="color:green;">2. variable extraction</mark>

_Among the options provided, "variable extraction" is not a variable transformation method. Variable extraction involves creating new variables from existing ones, typically by applying dimensionality reduction techniques like Principal Component Analysis (PCA) or feature selection methods. The other methods listed, such as variable aggregation, variable decomposition, and variable scaling, all involve altering or modifying existing variables rather than extracting new ones._

See chapter:

[#variable-transformation-methods](../3.-data-pre-processing/3.4-data-quality-cleansing-and-transformation.md#variable-transformation-methods "mention")

</details>

***

## Question 7

The evaluation of a regression model focuses on how ...

1. the relevant variables are correlated to the target variable.
2. much computational time was required to obtain the predictions.
3. close the model's output is to the target output.
4. the model's output is implemented within the buisness.

_**(3 points)**_

<details>

<summary>Answer</summary>

<mark style="color:green;">3. close the model's output is to the target output.</mark>

_In regression model evaluation, the primary focus is on measuring how closely the model's predictions align with the actual target values. This alignment is assessed using metrics like mean squared error (MSE) or R-squared. It's important to note that the other options mentioned, such as assessing the correlation between relevant variables and the target, evaluating computational time, or considering the model's implementation in a business context, are typically associated with the evaluation of classification models, not regression models._

</details>

***

## Question 8

In normal distribution, 99,7% of the values are within standard deviation equal ...

1. positive 1 and negative 1
2. positive 3 and negative 3
3. positive 4 and negative 4
4. positive 2 and negative 2

_**(3 points)**_

<details>

<summary>Answer</summary>

<mark style="color:green;">2. positive 3 and negative 3</mark>

In a normal distribution, which is a commonly observed statistical distribution in various natural phenomena, such as heights, IQ scores, or errors in measurements, the majority of the data falls within a certain range of standard deviations from the mean. This range is often referred to as "standard deviation intervals."

The provided question is related to the empirical rule, also known as the 68-95-99.7 rule, which is a guideline for understanding the spread of data in a normal distribution:

1. Approximately 68% of the values fall within one standard deviation above or below the mean.
2. About 95% of the values fall within two standard deviations above or below the mean.
3. Remarkably, roughly 99.7% of the values fall within three standard deviations above or below the mean.

So, in the context of the question, when considering a normal distribution, 99.7% of the values are indeed within standard deviation intervals of **positive 3 and negative 3** from the mean. This is a fundamental concept in statistics and probability, often used to assess data's variability and understand how extreme or common certain observations are within a given dataset.

<img src="image.png" alt="Alt text" data-size="original">

</details>

***

## Question 9

The main reason for removing the duplicated data records from the dataset is to ...

1. reduce the size of the training set.
2. increase the accuracy of the model.
3. increase the relevancy of the variables.
4. reduce computational time.

_**(3 points)**_

<details>

<summary>Answer</summary>

<mark style="color:green;">4. reduce computational time.</mark>

_The main reason for removing the duplicated data records from the dataset is to reduce computational time. The other options listed, such as reducing the size of the training set, increasing the accuracy of the model, and increasing the relevancy of the variables, are all examples of the benefits of removing duplicated data records._

</details>

***

## Question 10 ?

Which of the following type of information is operational on motor car manufacturing?

1. Decision on introducing a new model
2. Assessing competitor car
3. Scheduling production
4. Computing sales tax collected

_**(3 points)**_

<details>

<summary>Answer</summary>

<mark style="color:green;">3. Scheduling production</mark>

Operational information is data and knowledge that is directly related to the day-to-day operations and processes of an organization or industry. In the context of motor car manufacturing, various types of information play crucial roles in ensuring the smooth and efficient production of vehicles. Let's provide context for each of the options:

1. **Decision on introducing a new model:** This type of information is strategic and often involves long-term planning. It pertains to decisions made by top-level management and product development teams. While it's vital for the future of the company, it's not typically considered operational information. Instead, it falls under the category of strategic planning and product development.
2. **Assessing competitor cars:** Assessing competitor cars is important for market research and understanding consumer preferences, which can influence future product development and marketing strategies. This information is valuable but is more closely associated with market analysis and competitive intelligence, which are part of strategic planning rather than day-to-day operations.
3. **Scheduling production:** Scheduling production is a quintessential example of operational information in motor car manufacturing. It involves managing the assembly line, allocating resources, and coordinating the activities of various departments (e.g., manufacturing, logistics) to ensure that cars are produced efficiently and on time. Operational decisions in production scheduling have an immediate impact on the manufacturing process.
4. **Computing sales tax collected:** While calculating sales tax is essential for financial and regulatory compliance, it is primarily a financial transaction and accounting task. This information is related to tax reporting and financial management, which is crucial for a company's financial health. However, it is not typically considered operational information in the context of motor car manufacturing.

In summary, "Scheduling production" is a type of information that directly relates to the day-to-day operations of motor car manufacturing. The other options involve strategic planning, market analysis, and financial management, which are important but fall into different categories of information within the industry.

</details>

***

## Question 11

How does the receiver recognize the end of a bit stream in asynchronous serial data transmission?

1. The stream has constant period.
2. The stop bit alerts the receiver that the stream has ended.
3. the stream has a consequent idle gap of 1s or 0s bits.
4. the stop bit is always 1.

_**(3 points)**_

<details>

<summary>Answer</summary>

<mark style="color:green;">2. The stop bit alerts the receiver that the stream has ended.</mark>

In asynchronous serial data transmission, where data is sent one bit at a time without a shared clock signal between the sender and receiver, it's essential for the receiver to be able to recognize the boundaries of individual bits and bytes. The question addresses how the receiver identifies the end of a bit stream, and here's the context for each option:

1. **The stream has constant period:** This option suggests that the bit stream maintains a consistent timing pattern. However, asynchronous transmission does not rely on a fixed time period between bits, so this statement is not accurate. In asynchronous transmission, bits are sent with varying time intervals, and synchronization is achieved through start and stop bits.
2. **The stop bit alerts the receiver that the stream has ended:** This is the correct answer. In asynchronous serial communication, each byte of data is typically framed with a start bit, data bits, an optional parity bit, and one or more stop bits. The stop bit(s) follow the data bits and signal the end of the byte. When the receiver detects the stop bit(s), it knows that it has reached the end of the current byte and is ready to receive the next one.
3. **The stream has a consequent idle gap of 1s or 0s bits:** This option suggests that the receiver identifies the end of the bit stream by detecting a continuous sequence of idle (1s or 0s) bits. While idle bits are used to distinguish between consecutive bytes, they are not necessarily always 1s or 0s. The presence of an idle gap does not serve as a universal indicator of the end of data; it's the stop bit that performs this role.
4. **The stop bit is always 1:** In asynchronous serial communication, the stop bit(s) can be either 1 or 0, depending on the configuration. It's not a requirement for the stop bit to be always 1, and this statement does not accurately represent how the receiver recognizes the end of a bit stream.

In summary, option 2, "The stop bit alerts the receiver that the stream has ended," correctly describes how the receiver identifies the end of a bit stream in asynchronous serial data transmission. The stop bit serves as a clear indicator that one byte has ended, allowing the receiver to prepare for the reception of the next byte.

</details>

***

## Question 12

When does anchoring bias occur?

1. When decision-makers allocate similar weights to all objectives.
2. When the estimation of a numerical values is based on an initial value.
3. when people tend to prefer gambles with explicitly stated probabilities over gambles with diffuse probabilities.
4. when there is an emotional predisposition for, or against, a specific outcome.

_**(3 points)**_

<details>

<summary>Answer</summary>

<mark style="color:green;">2. When the estimation of a numerical values is based on an initial value.</mark>

Anchoring bias is a cognitive bias that occurs in decision-making and judgment processes. It influences how individuals make assessments or estimations by giving disproportionate weight to the first piece of information encountered, often referred to as the "anchor." Here's the context for each of the options:

1. **When decision-makers allocate similar weights to all objectives:** This option appears to describe a situation where decision-makers treat all objectives equally, but it doesn't directly relate to anchoring bias. Anchoring bias is specifically associated with the initial information or values used in estimations and judgments, not necessarily how weights are assigned to objectives.
2. **When the estimation of a numerical value is based on an initial value:** This is the correct answer. Anchoring bias occurs when individuals rely heavily on an initial piece of information, often an arbitrary or irrelevant value, when making numerical estimations or judgments. Subsequent judgments are then biased in relation to this initial anchor, even if it has no logical relevance to the decision.
3. **When people tend to prefer gambles with explicitly stated probabilities over gambles with diffuse probabilities:** This option appears to describe a preference for explicit information over vague or ambiguous information in decision-making, but it does not directly relate to anchoring bias. Anchoring bias specifically pertains to how the initial anchor influences numerical estimations.
4. **When there is an emotional predisposition for, or against, a specific outcome:** This option refers to emotional biases, which can influence decisions but are distinct from anchoring bias. Anchoring bias is primarily concerned with the reliance on the first piece of information as a reference point for subsequent judgments.

In summary, anchoring bias occurs when individuals base their numerical estimations or judgments on an initial value, often unrelated to the decision at hand. This initial value, or anchor, then influences subsequent judgments, leading to biased assessments.

</details>

***

## Question 13

Operational information is required by ...

1. line managers
2. middle managers
3. top managers
4. all workers

_**(3 points)**_

<details>

<summary>Answer</summary>

<mark style="color:green;">1. line managers</mark>

Operational information plays a critical role in organizational decision-making and management, and its relevance varies depending on the level of management within the organization. Here's the context for each of the options:

1. **Line managers:** This is the correct answer. Line managers are typically responsible for overseeing day-to-day operations and the front-line workers who carry out tasks. They require operational information to make immediate decisions related to production, quality control, and workforce management. Operational information helps line managers ensure that tasks are completed efficiently and that production goals are met.
2. **Middle managers:** Middle managers are often responsible for coordinating and managing various departments or teams within an organization. While they do require operational information, they also deal with more strategic and tactical aspects of management. They rely on a combination of operational and strategic information to make decisions that align with the organization's goals.
3. **Top managers:** Top managers, such as CEOs and executives, are primarily concerned with high-level strategic decisions that shape the organization's direction. They rely less on operational information and more on strategic and financial data to set long-term goals, allocate resources, and make decisions that impact the organization as a whole.
4. **All workers:** While operational information can be useful for workers to understand their immediate tasks and goals, it is not typically required by all workers in the same way it is for line managers. Workers may receive operational instructions and updates relevant to their specific roles, but they may not need access to all operational information across the organization.

In summary, operational information is particularly essential for line managers who oversee day-to-day operations and need real-time data to manage tasks and workflows efficiently. Middle and top managers focus on a broader range of information, including strategic and financial data, to make decisions that align with the organization's objectives. Workers receive operational information relevant to their specific roles but do not require all operational data.

</details>

***

## Question 14

which of the following is a characteristic of asynchronous serial data transmission?

1. Bit stream has start and stop bits.
2. Any gaps among the streams are filled with idle streams of 0s or 1s bits.
3. Fast, with no additional overhead.
4. constant period between transmissions.

_**(3 points)**_

<details>

<summary>Answer</summary>

<mark style="color:green;">1. Bit stream has start and stop bits.</mark>

Asynchronous serial data transmission is a common method of sending data in a sequential bit-by-bit manner without a shared clock signal between the sender and receiver. To provide context, let's examine each of the options:

1. **Bit stream has start and stop bits:** This is the correct answer. In asynchronous serial communication, each byte of data is typically framed with a start bit, data bits (e.g., 8 bits for the data itself), an optional parity bit, and one or more stop bits. The start bit signals the beginning of a data byte, and the stop bit(s) signal the end. This framing mechanism ensures that the receiver can identify and correctly interpret the individual bytes within the stream.
2. **Any gaps among the streams are filled with idle streams of 0s or 1s bits:** While it is possible to insert idle or padding bits between data bytes in certain serial communication protocols, this is not a universal characteristic of asynchronous serial transmission. The insertion of idle bits is protocol-specific and depends on the communication standard being used. It is not a fundamental characteristic of all asynchronous serial communication.
3. **Fast, with no additional overhead:** Asynchronous serial transmission can be fast, but the speed at which data can be transmitted depends on factors such as the communication protocol, hardware capabilities, and the length of the data frame. Additionally, there is inherent overhead in asynchronous communication due to the need for start and stop bits, which are essential for framing but do add some extra bits to the transmitted data.
4. **Constant period between transmissions:** Asynchronous serial communication does not rely on a constant period between transmissions. Instead, the time intervals between individual bits or bytes can vary, making it asynchronous. The receiver relies on the start bit to identify the beginning of a new byte and does not require a constant timing signal.

In summary, the key characteristic of asynchronous serial data transmission is that the bit stream is framed with start and stop bits to delineate individual bytes within the stream. This framing mechanism allows the receiver to correctly interpret the data. Other characteristics, such as idle bits or transmission speed, can vary depending on the specific communication protocol and settings.

</details>

***

## Question 15

What is the objective of a regression model?

_**(6 points)**_

<details>

<summary>Answer</summary>

<mark style="color:green;">The objective of a regression model is to predict the value of a target variable in a new situation (3 points),given the remainder of the variables values in previouse situations (3 points).</mark>

</details>

***

## Question 16

What are the two types of data transmission?

_**(6 points)**_

<details>

<summary>Answer</summary>

<mark style="color:green;">Manual transmission (3 points)Electronic transmission (3 points)Alternativly:SynchronousAsynchronous</mark>

Data transmission refers to the process of sending data from one location to another, and it can occur through various methods. The question asks about the two main types of data transmission, and here's the context for each of the options provided:

1. **Manual transmission:** Manual data transmission typically involves humans physically transferring data from one place to another, often using manual methods such as writing, typing, or printing. For example, delivering a handwritten letter, typing and mailing a document, or physically handing over a storage device (e.g., USB drive) are examples of manual data transmission. This method is not automated and relies on human intervention.
2. **Electronic transmission:** Electronic data transmission, on the other hand, involves the use of electronic devices and communication technologies to send data electronically from one location to another. It is automated and often occurs over networks or communication channels, including the internet. Examples include sending emails, transferring files over the internet, or transmitting data between electronic devices through wired or wireless connections.

Alternatively, another common way to classify data transmission is based on its timing and synchronization:

1. **Synchronous transmission:** In synchronous transmission, data is sent in a continuous stream with a fixed and synchronized timing signal shared between the sender and receiver. This synchronization ensures that data is transmitted at regular intervals, making it suitable for high-speed data transfer.
2. **Asynchronous transmission:** Asynchronous transmission, as discussed in a previous context, is a method where data is sent bit by bit without a shared clock signal. Instead, each data byte is framed with start and stop bits to delineate it from the rest of the stream. This method is commonly used for tasks that do not require high-speed transmission.

In summary, data transmission can be broadly categorized as manual (involving human intervention) or electronic (involving automated electronic devices and technologies). Alternatively, it can be categorized based on synchronization as synchronous (with shared timing) or asynchronous (without shared timing). The choice of transmission method depends on the specific needs of the data transfer task and the available technologies.

</details>

***

## Question 17

Explain in detail, how are the bubble chart, bar chart, and pie chart each used to visualize data?

_**(18 points)**_

<details>

<summary>Answer</summary>

* **A bubble chart** is used to visualize a dataset with two to four variables (2 points), where the first two variables are displayed as axes values (2 points), and the third and fourth variables are displayed as color and size, respectively (2 points).
* **A bar chart** displays a variable's value as a bar length (3 points), to indicate its density (3 points). with respect to the other variables.
* **The pie chart** is used to show proportions (3 points), of a whole, with the total of the variables' values being 100% (3 points).

</details>

***

## Question 18

1. What is the gradient decent concept in the back propagation algorithm?
2. how is it applied in neural networks?

_**(18 points)**_

<details>

<summary>Answer</summary>

1. **Gradient decent** The gradient decent concept is designed to act like gravety (3 points), where the current weight ($$w_t$$) moves to its updated weight ($$w_{t+1}$$) in the direction of the local (hopefully global) minimum of the overall network error (3 points). The assumption of the initial weights plays a significant role in the networks performance (3 points), and the network, through the gradient concept, will reach its stable position at a minimum value after some weight updates (3 points).
2. **The back propagation algorithm** of the network uses the current error metric and recursivly calculates (using gradient decent --> chain rule) how the network weights need to be changed (3 points). The idea is that since there is no analytical formula to do this in one step for all weights, we work backwards through all layers (1 point) and calculate how the weights need to be updated to achieve this reduced error value (2 points).

</details>

***
\n\n---\n\n## Navigation\n\n- **Parent**: [[data-science.iu-dlmbdsa01.exam-prep]]\n- **Course**: [[data-science.iu-dlmbdsa01]]\n